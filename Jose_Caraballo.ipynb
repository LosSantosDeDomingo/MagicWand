{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LosSantosDeDomingo/MagicWand/blob/main/Jose_Caraballo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf22435a-db43-4704-b26a-55efb41ed548",
      "metadata": {
        "id": "bf22435a-db43-4704-b26a-55efb41ed548"
      },
      "outputs": [],
      "source": [
        "# Jose Caraballo\n",
        "# Homework 2\n",
        "# 02/16/2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34c6039d-5119-4c9f-92bc-78dfd9f84a42",
      "metadata": {
        "id": "34c6039d-5119-4c9f-92bc-78dfd9f84a42"
      },
      "outputs": [],
      "source": [
        "# Import Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62fb5672-6f5f-472e-831e-354d4a6883d4",
      "metadata": {
        "id": "62fb5672-6f5f-472e-831e-354d4a6883d4"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "def centerData(dataset):\n",
        "    mean = dataset.mean()\n",
        "    centeredDataset = dataset - mean\n",
        "\n",
        "    return centeredDataset\n",
        "\n",
        "\n",
        "def calculateCovarianceMatrix(centeredDataset):\n",
        "    dotProduct = np.dot(centeredDataset.T, centeredDataset)\n",
        "    normalization = centeredDataset.shape[0] - 1\n",
        "    covarianceMatrix = dotProduct / normalization\n",
        "\n",
        "    return covarianceMatrix\n",
        "\n",
        "def centerKernel(kernel):\n",
        "    dummyElement = kernel.shape[0]\n",
        "    dummyMatrix = np.ones((dummyElement, dummyElement)) / dummyElement\n",
        "    meanRow = np.dot(dummyMatrix, kernel)\n",
        "    meanColumn = np.dot(kernel, dummyMatrix)\n",
        "    totalMean = np.dot(dummyMatrix , meanColumn)\n",
        "    centeredKernel = kernel - meanRow - meanColumn + totalMean\n",
        "\n",
        "    return centeredKernel\n",
        "\n",
        "def eigenDecomposition(dataset):\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(dataset)\n",
        "    sortedEigen = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvalues = eigenvalues[sortedEigen]\n",
        "    eigenvectors = eigenvectors[:,sortedEigen]\n",
        "\n",
        "    return eigenvalues, eigenvectors\n",
        "\n",
        "def performPCA(centeredDataset, desiredVarianceRatio, eigenvalues, eigenvectors):\n",
        "    # Determine the Variance Ratio\n",
        "    absEigenvalues = np.abs(eigenvalues)\n",
        "    sumEigenvalues = np.sum(absEigenvalues)\n",
        "    varianceRatio = absEigenvalues / sumEigenvalues\n",
        "    cumulativeVarianceRatio = np.cumsum(varianceRatio)\n",
        "\n",
        "    # Traverse the Cumulative Variance Ratio to determine the Desired Variance Ratio\n",
        "    eigenvaluesCounter = 0\n",
        "\n",
        "    for i in cumulativeVarianceRatio:\n",
        "        eigenvaluesCounter += 1\n",
        "        if i >= desiredVarianceRatio:\n",
        "            foundVarianceRatio = i\n",
        "            print(\"The Needed Amount of Eigenvalues:\", eigenvaluesCounter)\n",
        "            print(\"Appropriate Variance Ratio:\", foundVarianceRatio)\n",
        "            break\n",
        "\n",
        "    PCA = np.dot(centeredDataset, eigenvectors[:,:eigenvaluesCounter])\n",
        "\n",
        "    return PCA, eigenvaluesCounter, foundVarianceRatio\n",
        "\n",
        "def weightedKernelSum(alpha, beta, kernelAlpha, kernelBeta):\n",
        "   weightedSum = (alpha * kernelAlpha) + (beta * kernelBeta)\n",
        "\n",
        "   return weightedSum\n",
        "\n",
        "def kernelRBF(dataset):\n",
        "    # Initialize Kernel\n",
        "    # Error Handling for numpy\n",
        "    if hasattr(dataset, 'to_numpy'):\n",
        "        numpyDataset = dataset.to_numpy()\n",
        "    else:\n",
        "        numpyDataset = dataset\n",
        "\n",
        "    dataPoints = dataset.shape[0]\n",
        "    matrixRBF = np.zeros((dataPoints, dataPoints))\n",
        "    features = dataset.shape[1]\n",
        "    gamma = 1 / features\n",
        "\n",
        "    # Create Kernel\n",
        "    for i in range(dataPoints):\n",
        "        for j in range(dataPoints):\n",
        "            difference = numpyDataset[i] - numpyDataset[j]\n",
        "            distanceSquared = np.dot(difference, difference)\n",
        "            matrixRBF[i, j] = np.exp(-gamma * distanceSquared)\n",
        "\n",
        "    return matrixRBF\n",
        "\n",
        "def kernelPoly(dataset):\n",
        "    # Initialize Kernel\n",
        "    # Error Handling for numpy\n",
        "    if hasattr(dataset, 'to_numpy'):\n",
        "        numpyDataset = dataset.to_numpy()\n",
        "    else:\n",
        "        numpyDataset = dataset\n",
        "\n",
        "    dataPoints = dataset.shape[0]\n",
        "    matrixPoly = np.zeros((dataPoints, dataPoints))\n",
        "    degree = 3\n",
        "    coefficient = 1\n",
        "    features = dataset.shape[1]\n",
        "    gamma = 1 / features\n",
        "\n",
        "    # Create Kernel\n",
        "    for i in range(dataPoints):\n",
        "        for j in range(dataPoints):\n",
        "            dotProduct = np.dot(numpyDataset[i], numpyDataset[j])\n",
        "            matrixPoly[i, j] = (gamma * dotProduct + coefficient) ** degree\n",
        "\n",
        "    return matrixPoly\n",
        "\n",
        "def kernelLinear(dataset):\n",
        "    # Initialize Kernel\n",
        "    # Error Handling for numpy\n",
        "    if hasattr(dataset, 'to_numpy'):\n",
        "        numpyDataset = dataset.to_numpy()\n",
        "    else:\n",
        "        numpyDataset = dataset\n",
        "\n",
        "    dataPoints = dataset.shape[0]\n",
        "    matrixLinear = np.zeros((dataPoints, dataPoints))\n",
        "    numpyDataset = dataset.to_numpy()\n",
        "\n",
        "    # Create Kernel\n",
        "    for i in range(dataPoints):\n",
        "        for j in range(dataPoints):\n",
        "            dotProduct = np.dot(numpyDataset[i], numpyDataset[j])\n",
        "            matrixLinear[i, j] = dotProduct\n",
        "            matrixLinear[j, i] = dotProduct\n",
        "\n",
        "    return matrixLinear\n",
        "\n",
        "def crossKernelRBF(dataset1, dataset2):\n",
        "    # Initialize Kernel\n",
        "    # Error Handling for numpy\n",
        "    if hasattr(dataset1, 'to_numpy'):\n",
        "        numpyDataset1 = dataset1.to_numpy()\n",
        "    else:\n",
        "        numpyDataset1 = dataset1\n",
        "    if hasattr(dataset2, 'to_numpy'):\n",
        "        numpyDataset2 = dataset2.to_numpy()\n",
        "    else:\n",
        "        numpyDataset2 = dataset2\n",
        "\n",
        "    dataPoint1 = numpyDataset1.shape[0]\n",
        "    dataPoint2 = numpyDataset2.shape[0]\n",
        "    features = numpyDataset1.shape[1]\n",
        "    gamma = 1 / features\n",
        "    crossMatrixRBF = np.zeros((dataPoint1, dataPoint2))\n",
        "\n",
        "    # Create Kernel\n",
        "    for i in range(dataPoint1):\n",
        "        for j in range(dataPoint2):\n",
        "            difference = numpyDataset1[i] - numpyDataset2[j]\n",
        "            distanceSquared = np.dot(difference, difference)\n",
        "            crossMatrixRBF[i, j] = np.exp(-gamma * distanceSquared)\n",
        "    return crossMatrixRBF\n",
        "\n",
        "def crossKernelPoly(dataset1, dataset2):\n",
        "    # Initialize Kernel\n",
        "    # Error Handling for numpy\n",
        "    if hasattr(dataset1, 'to_numpy'):\n",
        "        numpyDataset1 = dataset1.to_numpy()\n",
        "    else:\n",
        "        numpyDataset1 = dataset1\n",
        "    if hasattr(dataset2, 'to_numpy'):\n",
        "        numpyDataset2 = dataset2.to_numpy()\n",
        "    else:\n",
        "        numpyDataset2 = dataset2\n",
        "\n",
        "    dataPoint1 = numpyDataset1.shape[0]\n",
        "    dataPoint2 = numpyDataset2.shape[0]\n",
        "    features = numpyDataset1.shape[1]\n",
        "    gamma = 1 / features\n",
        "    crossMatrixPoly = np.zeros((dataPoint1, dataPoint2))\n",
        "    degree = 3\n",
        "    coefficient = 1\n",
        "\n",
        "    # Create Kernel\n",
        "    for i in range(dataPoint1):\n",
        "        for j in range(dataPoint2):\n",
        "            dotProduct = np.dot(numpyDataset1[i], numpyDataset2[j])\n",
        "            crossMatrixPoly[i, j] = (gamma * dotProduct + coefficient) ** degree\n",
        "\n",
        "    return crossMatrixPoly\n",
        "\n",
        "def crossKernelLinear(dataset1, dataset2):\n",
        "    # Initialize Kernel\n",
        "    # Error Handling for numpy\n",
        "    if hasattr(dataset1, 'to_numpy'):\n",
        "        numpyDataset1 = dataset1.to_numpy()\n",
        "    else:\n",
        "        numpyDataset1 = dataset1\n",
        "    if hasattr(dataset2, 'to_numpy'):\n",
        "        numpyDataset2 = dataset2.to_numpy()\n",
        "    else:\n",
        "        numpyDataset2 = dataset2\n",
        "\n",
        "    dataPoint1 = numpyDataset1.shape[0]\n",
        "    dataPoint2 = numpyDataset2.shape[0]\n",
        "    crossMatrixLinear = np.zeros((dataPoint1, dataPoint2))\n",
        "\n",
        "    # Create Kernel\n",
        "    for i in range(dataPoint1):\n",
        "        for j in range(dataPoint2):\n",
        "            crossMatrixLinear[i, j] = np.dot(numpyDataset1[i], numpyDataset2[j])\n",
        "\n",
        "    return crossMatrixLinear\n",
        "\n",
        "def centerCrossKernel(testKernel, trainKernel):\n",
        "    trainMean = np.mean(trainKernel)\n",
        "    trainColumnMean = np.mean(trainKernel, axis=0)\n",
        "    testRowMean = np.mean(testKernel, axis=1, keepdims=True)\n",
        "    centeredTestKernel = testKernel - testRowMean - trainColumnMean + trainMean\n",
        "\n",
        "    return centeredTestKernel\n",
        "\n",
        "def accuracyMetric(yTest, yPredict):\n",
        "    accuracyScore = 100 * accuracy_score(yTest,yPredict)\n",
        "\n",
        "    return accuracyScore\n",
        "\n",
        "\n",
        "def naiveGaussianClassifier(xTrain, xTest, yTrain, yTest):\n",
        "    naiveGaussian = GaussianNB()\n",
        "    naiveGaussian.fit(xTrain, yTrain)\n",
        "    yPredict = naiveGaussian.predict(xTest)\n",
        "\n",
        "    return xTrain, xTest, yTrain, yTest, yPredict\n",
        "\n",
        "def calculateTopFeatures(dataFrame, featureAmount):\n",
        "    centeredDataFrame = centerData(dataFrame)\n",
        "    covMatrix = calculateCovarianceMatrix(centeredDataFrame)\n",
        "    diagonalCovMatrix = np.diag(covMatrix)\n",
        "    sortedDiagonalCovMatrix = np.argsort(diagonalCovMatrix)[::-1]\n",
        "    topFeatures_ = sortedDiagonalCovMatrix[:featureAmount]\n",
        "    topFeaturesMatrix_ = dataset.iloc[:, topFeatures_]\n",
        "\n",
        "    return topFeaturesMatrix_\n",
        "\n",
        "def performRBFKernelPCA(dataset, desiredVarianceRatio):\n",
        "    RBF = kernelRBF(dataset)\n",
        "    centeredRBF = centerKernel(RBF)\n",
        "    eigenvalues, eigenvectors = eigenDecomposition(centeredRBF)\n",
        "    PCA, neededEigenvalues, VarianceRatio = performPCA(centeredRBF, desiredVarianceRatio, eigenvalues, eigenvectors)\n",
        "\n",
        "    return centeredRBF, PCA, neededEigenvalues, VarianceRatio\n",
        "\n",
        "def performPolyKernelPCA(dataset, desiredVarianceRatio):\n",
        "    Poly = kernelPoly(dataset)\n",
        "    centeredPoly = centerKernel(Poly)\n",
        "    eigenvalues, eigenvectors = eigenDecomposition(centeredPoly)\n",
        "    PCA, neededEigenvalues, VarianceRatio = performPCA(centeredPoly, desiredVarianceRatio, eigenvalues, eigenvectors)\n",
        "\n",
        "    return centeredPoly, PCA, neededEigenvalues, VarianceRatio\n",
        "\n",
        "def performLinearKernelPCA(dataset, desiredVarianceRatio):\n",
        "    Linear = kernelLinear(dataset)\n",
        "    centeredLinear = centerKernel(Linear)\n",
        "    eigenvalues, eigenvectors = eigenDecomposition(centeredLinear)\n",
        "    PCA, neededEigenvalues, VarianceRatio = performPCA(centeredLinear, desiredVarianceRatio, eigenvalues, eigenvectors)\n",
        "\n",
        "    return centeredLinear, PCA, neededEigenvalues, VarianceRatio\n",
        "\n",
        "def fullPCA(dataset, desiredVarianceRatio):\n",
        "    centeredDataFrame = centerData(dataFrame)\n",
        "    covMatrix = calculateCovarianceMatrix(centeredDataFrame)\n",
        "    eigenvalue, eigenvector = eigenDecomposition(covMatrix)\n",
        "    PCA, neededEigenvalues, VarianceRatio = performPCA(covMatrix, desiredVarianceRatio, eigenvalues, eigenvectors)\n",
        "\n",
        "    return covMatrix, PCA, neededEigenvalues, VarianceRatio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d44ea8b-e023-4d7c-8046-c6c426a23d36",
      "metadata": {
        "id": "2d44ea8b-e023-4d7c-8046-c6c426a23d36"
      },
      "outputs": [],
      "source": [
        "# Read Data\n",
        "lungData = pd.read_csv(\"Lung.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6bf9eb8-0201-45ec-9044-9beb1b0d8d2c",
      "metadata": {
        "id": "d6bf9eb8-0201-45ec-9044-9beb1b0d8d2c",
        "outputId": "cf2c610d-749a-4950-80a1-2e8f9f85cc03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Covariance Matrix:\n",
            " [[ 3.64132003e+07  3.63754207e+07  3.63903211e+07 ...  2.05735354e+05\n",
            "   1.37170778e+07 -5.05024303e+01]\n",
            " [ 3.63754207e+07  3.63447280e+07  3.63557087e+07 ...  2.02655549e+05\n",
            "   1.35841085e+07 -5.17544440e+01]\n",
            " [ 3.63903211e+07  3.63557087e+07  3.63742618e+07 ...  2.04431667e+05\n",
            "   1.39865996e+07 -5.32241424e+01]\n",
            " ...\n",
            " [ 2.05735354e+05  2.02655549e+05  2.04431667e+05 ...  1.47418361e+05\n",
            "   8.95987577e+05 -1.25884123e+01]\n",
            " [ 1.37170778e+07  1.35841085e+07  1.39865996e+07 ...  8.95987577e+05\n",
            "   7.03172944e+08 -2.95837066e+02]\n",
            " [-5.05024303e+01 -5.17544440e+01 -5.32241424e+01 ... -1.25884123e+01\n",
            "  -2.95837066e+02  7.30344184e-01]]\n"
          ]
        }
      ],
      "source": [
        "# Part 1: Principal Component Analysis (PCA)\n",
        "# 1.1 Implement PCA from Scratch:\n",
        "# A. Compute the Covariance Matrix\n",
        "\n",
        "# Center Dataset\n",
        "centeredLungData = centerData(lungData)\n",
        "\n",
        "# Calculate and Display the Covariance Matrix\n",
        "covarianceMatrix = calculateCovarianceMatrix(centeredLungData)\n",
        "print(\"Covariance Matrix:\\n\", covarianceMatrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a868f1d-816e-44a1-bf81-af8760c30a34",
      "metadata": {
        "id": "4a868f1d-816e-44a1-bf81-af8760c30a34",
        "outputId": "94ef2fbe-b086-4149-c87a-ee18e998ef3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorted Eigenvalues:\n",
            " [ 1.77291275e+10+0.j  6.06036261e+09+0.j  2.54877425e+09+0.j ...\n",
            " -2.96954821e-10+0.j -4.55695923e-10+0.j -3.51129529e-08+0.j]\n",
            "\n",
            "Sorted Eigenvector:\n",
            " [[-2.36224092e-02+0.j -3.21901928e-02+0.j  4.51299988e-03+0.j ...\n",
            "   2.28750554e-03+0.j  9.09863298e-03+0.j -2.97084335e-02+0.j]\n",
            " [-2.35450150e-02+0.j -3.22210286e-02+0.j  4.55744430e-03+0.j ...\n",
            "   2.42228621e-03+0.j  9.16344813e-03+0.j -2.96883768e-02+0.j]\n",
            " [-2.36032857e-02+0.j -3.20342350e-02+0.j  4.52404866e-03+0.j ...\n",
            "   2.35472139e-03+0.j  9.52760287e-03+0.j -2.96439024e-02+0.j]\n",
            " ...\n",
            " [-8.51728975e-04+0.j  6.27632888e-04+0.j -1.59468875e-03+0.j ...\n",
            "   2.33676264e-03+0.j  9.25026628e-03+0.j -2.96765176e-02+0.j]\n",
            " [-5.12228931e-02+0.j  1.17124701e-01+0.j  1.72997865e-02+0.j ...\n",
            "   2.35311817e-03+0.j  9.26154590e-03+0.j -2.96808682e-02+0.j]\n",
            " [ 4.73735208e-08+0.j -5.75140730e-09+0.j  5.20943857e-07+0.j ...\n",
            "   2.24363107e-03+0.j  9.10400769e-03+0.j  1.63506550e-04+0.j]]\n"
          ]
        }
      ],
      "source": [
        "# A. Compute the Eigenvalues and Eigenvectors\n",
        "eigenvalue, eigenvector = eigenDecomposition(covarianceMatrix)\n",
        "print(\"Sorted Eigenvalues:\\n\", eigenvalue)\n",
        "print(\"\\nSorted Eigenvector:\\n\", eigenvector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c294a01-3377-4e0c-a497-06e2c50314ac",
      "metadata": {
        "id": "8c294a01-3377-4e0c-a497-06e2c50314ac",
        "outputId": "2848a915-fce4-412c-9f11-ca418478b43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centered Lung Data Shape: (1091, 1882)\n",
            "PCA Lung Data Shape: (1091, 2)\n"
          ]
        }
      ],
      "source": [
        "# B. Apply PCA Implementation to Reduce the Dimensionality of the Features in the Data Frame\n",
        "selectedEigenvectors = 2\n",
        "lungPCAData = np.dot(centeredLungData, eigenvector[:, :selectedEigenvectors])\n",
        "\n",
        "print(\"Centered Lung Data Shape:\", centeredLungData.shape)\n",
        "print(\"PCA Lung Data Shape:\", lungPCAData.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "152e097a-6c38-4b07-81d6-053083fee61b",
      "metadata": {
        "id": "152e097a-6c38-4b07-81d6-053083fee61b",
        "outputId": "acbb344a-5d2b-4779-95d3-cf6ea84d3388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Needed Amount of Eigenvalues: 12\n",
            "Appropriate Variance Ratio: 0.9821908623824441\n",
            "Centered Lung Data Shape: (1091, 1882)\n",
            "PCA Lung Data Shape: (1091, 12)\n"
          ]
        }
      ],
      "source": [
        "# C. Select an Appropriate Number of Principal Components to Retain A Significant Amount of Variance\n",
        "desiredVarianceRatio = 0.98\n",
        "lungPCAData, neededEigenvalues, calculatedVarianceRatio = performPCA(centeredLungData, desiredVarianceRatio, eigenvalue, eigenvector)\n",
        "\n",
        "# Display Shape\n",
        "print(\"Centered Lung Data Shape:\", centeredLungData.shape)\n",
        "print(\"PCA Lung Data Shape:\", lungPCAData.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d467eb7c-a65e-4c79-a531-5646de004bce",
      "metadata": {
        "id": "d467eb7c-a65e-4c79-a531-5646de004bce",
        "outputId": "f6de1c23-cc36-497e-92b4-a01058c8221c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Lung Data Shape: (1091, 1882)\n",
            "Lung Data Shape with sklearn: (1091, 12)\n",
            "\n",
            "Variance Ratios with sklearn\n",
            " [0.53479798 0.18281045 0.07688361 0.04422609 0.03984111 0.0321145\n",
            " 0.02158253 0.01672605 0.01564304 0.00807935 0.00582232 0.00366384]\n",
            "\n",
            "Pricipal Components with sklearn\n",
            " [[-2.36224092e-02 -2.35450150e-02 -2.36032857e-02 ... -8.51728975e-04\n",
            "  -5.12228931e-02  4.73735208e-08]\n",
            " [ 3.21901928e-02  3.22210286e-02  3.20342350e-02 ... -6.27632888e-04\n",
            "  -1.17124701e-01  5.75140730e-09]\n",
            " [ 4.51299988e-03  4.55744430e-03  4.52404866e-03 ... -1.59468875e-03\n",
            "   1.72997865e-02  5.20943857e-07]\n",
            " ...\n",
            " [ 2.29352854e-03  2.54689541e-03  2.52296340e-03 ...  1.26622531e-03\n",
            "  -1.73913784e-01  2.72098241e-07]\n",
            " [-2.02407724e-01 -2.02409532e-01 -2.02728766e-01 ... -1.30647328e-04\n",
            "   4.76300628e-01  1.42455879e-06]\n",
            " [-1.20476790e-01 -1.20497462e-01 -1.20944036e-01 ...  1.88024080e-03\n",
            "   1.19152416e-01 -1.71007889e-06]]\n"
          ]
        }
      ],
      "source": [
        "# 1.2 PCA using scikit-learn:\n",
        "# A. Use the PCA Module from sklearn to Perfrom Dimensionality Reduction on the Dataset\n",
        "sklearnPCA = PCA(n_components=0.98)\n",
        "reducedLungData = sklearnPCA.fit_transform(centeredLungData)\n",
        "\n",
        "# Display Differences in Shape\n",
        "print(\"Original Lung Data Shape:\", lungData.shape)\n",
        "print(\"Lung Data Shape with sklearn:\", reducedLungData.shape)\n",
        "\n",
        "# Display Variance Ratio\n",
        "sklearnVarianceRatio = sklearnPCA.explained_variance_ratio_\n",
        "print(\"\\nVariance Ratios with sklearn\\n\", sklearnVarianceRatio)\n",
        "\n",
        "# Display Principal Components\n",
        "sklearnPrincipalComponents = sklearnPCA.components_\n",
        "print(\"\\nPricipal Components with sklearn\\n\", sklearnPrincipalComponents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad12f281-344a-41ac-bb13-709b19de610b",
      "metadata": {
        "id": "ad12f281-344a-41ac-bb13-709b19de610b",
        "outputId": "e4ecc5d5-6836-4f76-88b1-b3faf9a0f6d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From-Scratch Vs. Sklearn\n",
            "Total From-Scratch Variance: 0.9821908623824441\n",
            "Total Sklearn Variance: 0.9821908623824441\n",
            "\n",
            "Total From-Scratch Principal Components: 12\n",
            "Total Sklearn Principal Components: 12\n",
            "\n",
            "Total From-Scratch Components: 13092\n",
            "Total Sklearn Components: 13092\n",
            "\n",
            "From-Scratch Shape: (1091, 12)\n",
            "Sklearn Shape: (1091, 12)\n"
          ]
        }
      ],
      "source": [
        "# B. Compare the From-Scratch Implementation with the PCA\n",
        "# Module Compare Variance and the reduced feature set.\n",
        "# Total Variance Ratio\n",
        "totalSklearnVariance = np.sum(sklearnVarianceRatio)\n",
        "print(\"From-Scratch Vs. Sklearn\")\n",
        "print(\"Total From-Scratch Variance:\", calculatedVarianceRatio)\n",
        "print(\"Total Sklearn Variance:\", totalSklearnVariance)\n",
        "\n",
        "# Number of Principal Components\n",
        "print(\"\\nTotal From-Scratch Principal Components:\", neededEigenvalues)\n",
        "print(\"Total Sklearn Principal Components:\", sklearnPrincipalComponents.shape[0])\n",
        "\n",
        "# Number of Components\n",
        "totalComponents = np.size(lungPCAData)\n",
        "totalSklearnComponents = np.size(reducedLungData)\n",
        "print(\"\\nTotal From-Scratch Components:\", totalComponents)\n",
        "print(\"Total Sklearn Components:\", totalSklearnComponents)\n",
        "\n",
        "# Shape\n",
        "print(\"\\nFrom-Scratch Shape:\", lungPCAData.shape)\n",
        "print(\"Sklearn Shape:\", reducedLungData.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1007abe2-240a-4f98-a2f3-ef0bd995263f",
      "metadata": {
        "id": "1007abe2-240a-4f98-a2f3-ef0bd995263f",
        "outputId": "7e271860-dc45-43f1-fb38-6201eeb10dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RBF Kernel Matrix:\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# Part 2: Kernel PCA (KPCA)\n",
        "# 2.1 KPCA with RBF Kernel:\n",
        "# A. Implement Kernel PCA with the Radial Basis Function (RBF) Kernel from Scratch.\n",
        "kernelMatrixRBF = kernelRBF(lungData)\n",
        "print(\"RBF Kernel Matrix:\\n\", kernelMatrixRBF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84cffa6d-059b-4aab-8417-4d36f9b3c05e",
      "metadata": {
        "id": "84cffa6d-059b-4aab-8417-4d36f9b3c05e",
        "outputId": "446c7172-555b-4475-cf35-2f1a32f099f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centered RBF Kernel Matrix:\n",
            " [[ 9.99083410e-01 -9.16590284e-04 -9.16590284e-04 ... -9.16590284e-04\n",
            "  -9.16590284e-04 -9.16590284e-04]\n",
            " [-9.16590284e-04  9.99083410e-01 -9.16590284e-04 ... -9.16590284e-04\n",
            "  -9.16590284e-04 -9.16590284e-04]\n",
            " [-9.16590284e-04 -9.16590284e-04  9.99083410e-01 ... -9.16590284e-04\n",
            "  -9.16590284e-04 -9.16590284e-04]\n",
            " ...\n",
            " [-9.16590284e-04 -9.16590284e-04 -9.16590284e-04 ...  9.99083410e-01\n",
            "  -9.16590284e-04 -9.16590284e-04]\n",
            " [-9.16590284e-04 -9.16590284e-04 -9.16590284e-04 ... -9.16590284e-04\n",
            "   9.99083410e-01 -9.16590284e-04]\n",
            " [-9.16590284e-04 -9.16590284e-04 -9.16590284e-04 ... -9.16590284e-04\n",
            "  -9.16590284e-04  9.99083410e-01]]\n",
            "\n",
            "Centered RBF Kernel Matrix Shape: (1091, 1091)\n",
            "The Needed Amount of Eigenvalues: 1069\n",
            "Appropriate Variance Ratio: 0.9807339449541213\n",
            "RBF KPCA Lung Data Shape: (1091, 1069)\n"
          ]
        }
      ],
      "source": [
        "# B. Apply your KPCA Implementation to the Dataset.\n",
        "# Center Dataset\n",
        "centeredMatrixRBF = centerKernel(kernelMatrixRBF)\n",
        "print(\"Centered RBF Kernel Matrix:\\n\", centeredMatrixRBF)\n",
        "print(\"\\nCentered RBF Kernel Matrix Shape:\", centeredMatrixRBF.shape)\n",
        "\n",
        "# Compute and Sort the Eigenvalues and Eigenvectors\n",
        "eigenvaluesRBF, eigenvectorsRBF = eigenDecomposition(centeredMatrixRBF)\n",
        "\n",
        "# Apply PCA to the RBF Kernel\n",
        "kpcaRBF, neededEigenvaluesRBF, VarRatioRBF = performPCA(centeredMatrixRBF, desiredVarianceRatio, eigenvaluesRBF, eigenvectorsRBF)\n",
        "print(\"RBF KPCA Lung Data Shape:\", kpcaRBF.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62bbe0a4-f43b-43f3-9a0b-3689eef39568",
      "metadata": {
        "id": "62bbe0a4-f43b-43f3-9a0b-3689eef39568",
        "outputId": "df6a9a55-b076-4e21-f23f-441f161ecc5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polynomial Kernel Matrix:\n",
            " [[8.21982682e+24 4.62113325e+24 1.95915586e+24 ... 2.84024740e+24\n",
            "  2.26710834e+24 1.93601609e+24]\n",
            " [4.62113325e+24 2.72918021e+24 1.21895330e+24 ... 1.66226238e+24\n",
            "  1.37885868e+24 1.18547601e+24]\n",
            " [1.95915586e+24 1.21895330e+24 6.28469471e+23 ... 7.45057458e+23\n",
            "  6.48915781e+23 5.77310621e+23]\n",
            " ...\n",
            " [2.84024740e+24 1.66226238e+24 7.45057458e+23 ... 1.05619127e+24\n",
            "  8.45436977e+23 7.33697885e+23]\n",
            " [2.26710834e+24 1.37885868e+24 6.48915781e+23 ... 8.45436977e+23\n",
            "  8.55881991e+23 6.50137960e+23]\n",
            " [1.93601609e+24 1.18547601e+24 5.77310621e+23 ... 7.33697885e+23\n",
            "  6.50137960e+23 5.59631138e+23]]\n"
          ]
        }
      ],
      "source": [
        "# 2.2 KPCA with Polynomial Kernel:\n",
        "# A. Implement Kernel PCA with a Polynomial Kernel from Scratch.\n",
        "# Initialize Kernel\n",
        "kernelMatrixPoly = kernelPoly(lungData)\n",
        "print(\"Polynomial Kernel Matrix:\\n\", kernelMatrixPoly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1195241-d573-4c9f-98dd-b5e372e6bc1a",
      "metadata": {
        "id": "b1195241-d573-4c9f-98dd-b5e372e6bc1a",
        "outputId": "2f89501e-c077-4a85-cbc2-8c2c82062390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centered Polynomial Kernel Matrix:\n",
            " [[ 4.86363915e+24  2.05052781e+24  5.65342488e+21 ...  7.04501688e+23\n",
            "   2.15384198e+23 -9.17955634e+21]\n",
            " [ 2.05052781e+24  9.44157011e+23  5.10330925e+22 ...  3.12098906e+23\n",
            "   1.12716768e+23  2.58625988e+22]\n",
            " [ 5.65342488e+21  5.10330925e+22  7.76522612e+22 ...  1.19969769e+22\n",
            "  -1.23134919e+20  3.48002059e+22]\n",
            " ...\n",
            " [ 7.04501688e+23  3.12098906e+23  1.19969769e+22 ...  1.40887522e+23\n",
            "   1.41547898e+22  8.94419847e+21]\n",
            " [ 2.15384198e+23  1.12716768e+23 -1.23134919e+20 ...  1.41547898e+22\n",
            "   1.08621369e+23  9.40583918e+21]\n",
            " [-9.17955634e+21  2.58625988e+22  3.48002059e+22 ...  8.94419847e+21\n",
            "   9.40583918e+21  2.54275181e+22]]\n",
            "\n",
            "Centered Polynomial Kernel Matrix Shape: (1091, 1091)\n",
            "The Needed Amount of Eigenvalues: 22\n",
            "Appropriate Variance Ratio: 0.9805665858548569\n",
            "Polynomial KPCA Lung Data Shape: (1091, 22)\n"
          ]
        }
      ],
      "source": [
        "# B. Apply your KPCA Implementation to the Dataset.\n",
        "# Center Dataset\n",
        "centeredMatrixPoly = centerKernel(kernelMatrixPoly)\n",
        "print(\"Centered Polynomial Kernel Matrix:\\n\", centeredMatrixPoly)\n",
        "print(\"\\nCentered Polynomial Kernel Matrix Shape:\", centeredMatrixPoly.shape)\n",
        "\n",
        "# Compute and Sort the Eigenvalues and Eigenvectors\n",
        "eigenvaluesPoly, eigenvectorsPoly = eigenDecomposition(centeredMatrixPoly)\n",
        "\n",
        "# Apply PCA to the Polynomial Kernel\n",
        "kpcaPoly, neededEigenvaluesPoly, VarRatioPoly = performPCA(centeredMatrixPoly, desiredVarianceRatio, eigenvaluesPoly, eigenvectorsPoly)\n",
        "print(\"Polynomial KPCA Lung Data Shape:\", kpcaPoly.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed46d997-cdec-4062-b066-e7bf74342fdf",
      "metadata": {
        "id": "ed46d997-cdec-4062-b066-e7bf74342fdf",
        "outputId": "e59fa75a-c6a9-48eb-a2f4-859672335d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Kernel Matrix:\n",
            " [[3.79816511e+11 3.13474665e+11 2.35491885e+11 ... 2.66525238e+11\n",
            "  2.47235240e+11 2.34561071e+11]\n",
            " [3.13474665e+11 2.63004808e+11 2.01039766e+11 ... 2.22939047e+11\n",
            "  2.09472107e+11 1.99182206e+11]\n",
            " [2.35491885e+11 2.01039766e+11 1.61205929e+11 ... 1.70614604e+11\n",
            "  1.62935503e+11 1.56707385e+11]\n",
            " ...\n",
            " [2.66525238e+11 2.22939047e+11 1.70614604e+11 ... 1.91661025e+11\n",
            "  1.77956297e+11 1.69743064e+11]\n",
            " [2.47235240e+11 2.09472107e+11 1.62935503e+11 ... 1.77956297e+11\n",
            "  1.78686158e+11 1.63037731e+11]\n",
            " [2.34561071e+11 1.99182206e+11 1.56707385e+11 ... 1.69743064e+11\n",
            "  1.63037731e+11 1.55091110e+11]]\n"
          ]
        }
      ],
      "source": [
        "# 2.3 KPCA with Linear Kernel:\n",
        "# A. Implement Kernel PCA with a Linear Kernel from Scratch.\n",
        "# Create the Linear Kernel\n",
        "kernelMatrixLinear = kernelLinear(lungData)\n",
        "print(\"Linear Kernel Matrix:\\n\", kernelMatrixLinear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "271029d5-7ec6-454a-8828-968fa074ede7",
      "metadata": {
        "id": "271029d5-7ec6-454a-8828-968fa074ede7",
        "outputId": "70d65e25-215f-4991-80b2-8d5c8adac30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centered Linear Kernel Matrix:\n",
            " [[8.64994020e+10 5.21882661e+10 1.25151964e+10 ... 3.10442219e+10\n",
            "  1.53306856e+10 1.22554700e+10]\n",
            " [5.21882661e+10 3.37491183e+10 1.00937877e+10 ... 1.94887410e+10\n",
            "  9.59826172e+09 8.90731446e+09]\n",
            " [1.25151964e+10 1.00937877e+10 8.56966080e+09 ... 5.47400868e+09\n",
            "  1.37136880e+09 4.74220401e+09]\n",
            " ...\n",
            " [3.10442219e+10 1.94887410e+10 5.47400868e+09 ... 1.40161016e+10\n",
            "  3.88783503e+09 5.27355508e+09]\n",
            " [1.53306856e+10 9.59826172e+09 1.37136880e+09 ... 3.88783503e+09\n",
            "  8.19415686e+09 2.14468340e+09]\n",
            " [1.22554700e+10 8.90731446e+09 4.74220401e+09 ... 5.27355508e+09\n",
            "  2.14468340e+09 3.79701605e+09]]\n",
            "\n",
            "Centered Linear Kernel Matrix Shape: (1091, 1091)\n",
            "The Needed Amount of Eigenvalues: 12\n",
            "Appropriate Variance Ratio: 0.9821908623824412\n",
            "Linear KPCA Lung Data Shape: (1091, 12)\n"
          ]
        }
      ],
      "source": [
        "# B. Apply your KPCA Implementation to the Dataset.\n",
        "# Center Dataset\n",
        "centeredMatrixLinear = centerKernel(kernelMatrixLinear)\n",
        "print(\"Centered Linear Kernel Matrix:\\n\", centeredMatrixLinear)\n",
        "print(\"\\nCentered Linear Kernel Matrix Shape:\", centeredMatrixLinear.shape)\n",
        "\n",
        "# Compute and Sort the Eigenvalues and Eigenvectors\n",
        "eigenvaluesLinear, eigenvectorsLinear = eigenDecomposition(centeredMatrixLinear)\n",
        "\n",
        "# Apply PCA to the Linear Kernel\n",
        "kpcaLinear, neededEigenvaluesLinear, VarRatioLinear = performPCA(centeredMatrixLinear, desiredVarianceRatio, eigenvaluesLinear, eigenvectorsLinear)\n",
        "print(\"Linear KPCA Lung Data Shape:\", kpcaLinear.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b0511eb-af08-45e0-b5ba-9ddc83ac4de8",
      "metadata": {
        "id": "1b0511eb-af08-45e0-b5ba-9ddc83ac4de8",
        "outputId": "076e3a3e-8aa6-4250-8304-4d01184711d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polynomial RBF Kernel Matrix:\n",
            " [[ 2.43181958e+24  1.02526391e+24  2.82671244e+21 ...  3.52250844e+23\n",
            "   1.07692099e+23 -4.58977817e+21]\n",
            " [ 1.02526391e+24  4.72078506e+23  2.55165463e+22 ...  1.56049453e+23\n",
            "   5.63583839e+22  1.29312994e+22]\n",
            " [ 2.82671244e+21  2.55165463e+22  3.88261306e+22 ...  5.99848844e+21\n",
            "  -6.15674593e+19  1.74001029e+22]\n",
            " ...\n",
            " [ 3.52250844e+23  1.56049453e+23  5.99848844e+21 ...  7.04437608e+22\n",
            "   7.07739491e+21  4.47209923e+21]\n",
            " [ 1.07692099e+23  5.63583839e+22 -6.15674593e+19 ...  7.07739491e+21\n",
            "   5.43106845e+22  4.70291959e+21]\n",
            " [-4.58977817e+21  1.29312994e+22  1.74001029e+22 ...  4.47209923e+21\n",
            "   4.70291959e+21  1.27137590e+22]]\n",
            "\n",
            "Polynomial RBF Kernel Matrix Shape: (1091, 1091)\n",
            "The Needed Amount of Eigenvalues: 22\n",
            "Appropriate Variance Ratio: 0.9805665858548569\n",
            "Combined KPCA Lung Data Shape: (1091, 22)\n"
          ]
        }
      ],
      "source": [
        "# 2.4 Combining Kernels:\n",
        "# A. Combine Two Different Kernels (e.g., RBF and Polynomial) and Apply the Combined KPCA to the Dataset.\n",
        "alpha = 0.5\n",
        "beta = 0.5\n",
        "combinedPolyRBF = weightedKernelSum(alpha, beta, centeredMatrixPoly, centeredMatrixRBF)\n",
        "print(\"Polynomial RBF Kernel Matrix:\\n\", combinedPolyRBF)\n",
        "print(\"\\nPolynomial RBF Kernel Matrix Shape:\", combinedPolyRBF.shape)\n",
        "\n",
        "# Compute and Sort the Eigenvalues and Eigenvectors\n",
        "eigenvaluesPolyRBF, eigenvectorsPolyRBF = eigenDecomposition(combinedPolyRBF)\n",
        "\n",
        "# Apply PCA to the Combined Kernel\n",
        "kpcaPolyRBF, neededEigenvaluesPolyRBF, VarRatioPolyRBF = performPCA(combinedPolyRBF, desiredVarianceRatio, eigenvaluesPolyRBF, eigenvectorsPolyRBF)\n",
        "print(\"Combined KPCA Lung Data Shape:\", kpcaPolyRBF.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f616108f-c08f-4e8b-aed9-a557ebe58b75",
      "metadata": {
        "id": "f616108f-c08f-4e8b-aed9-a557ebe58b75"
      },
      "outputs": [],
      "source": [
        "# B. Evaluate the Classification Performance Using Accuracy Metrics for the Combined Kernels.\n",
        "newLungData = lungData.iloc[:,:-1].to_numpy()\n",
        "labelLungData = lungData.iloc[:,-1].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7841a1-6e17-4102-b4ab-f6074ce97e8d",
      "metadata": {
        "id": "6f7841a1-6e17-4102-b4ab-f6074ce97e8d",
        "outputId": "97f86aa1-2090-412f-ff46-1f7865ad576b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained RBF Kernel Matrix Shape: (1069, 1069)\n",
            "Tested RBF Kernel Matrix Shape: (22, 1069)\n",
            "\n",
            "Trained Polynominal Kernel Matrix Shape: (1069, 1069)\n",
            "Tested Polynominal Kernel Matrix Shape: (22, 1069)\n"
          ]
        }
      ],
      "source": [
        "# Train and Test Data\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "# Create the RBF Kernel\n",
        "# Trained Data\n",
        "xTrainRBF = kernelRBF(xTrain)\n",
        "centeredxTrainRBF = centerKernel(xTrainRBF)\n",
        "\n",
        "# Test Data\n",
        "xTestRBF = crossKernelRBF(xTest, xTrain)\n",
        "centeredxTestRBF = centerCrossKernel(xTestRBF, xTrainRBF)\n",
        "\n",
        "# Display\n",
        "print(\"Trained RBF Kernel Matrix Shape:\", centeredxTrainRBF.shape)\n",
        "print(\"Tested RBF Kernel Matrix Shape:\", centeredxTestRBF.shape)\n",
        "\n",
        "# Create the Polynomial Kernel\n",
        "# Trained Data\n",
        "xTrainPoly = kernelPoly(xTrain)\n",
        "centeredxTrainPoly = centerKernel(xTrainPoly)\n",
        "\n",
        "# Test Data\n",
        "xTestPoly = crossKernelPoly(xTest, xTrain)\n",
        "centeredxTestPoly = centerCrossKernel(xTestPoly, xTrainPoly)\n",
        "\n",
        "# Display\n",
        "print(\"\\nTrained Polynominal Kernel Matrix Shape:\", centeredxTrainPoly.shape)\n",
        "print(\"Tested Polynominal Kernel Matrix Shape:\", centeredxTestPoly.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b67fa6e-4924-48e9-a509-dea5432ec4c8",
      "metadata": {
        "id": "6b67fa6e-4924-48e9-a509-dea5432ec4c8",
        "outputId": "556f072e-fd1f-4e4d-e2f9-26849aba7fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained Polynomial RBF Kernel Matrix Shape: (1069, 1069)\n",
            "Test Polynomial RBF Kernel Matrix Shape: (22, 1069)\n",
            "The Needed Amount of Eigenvalues: 22\n",
            "Appropriate Variance Ratio: 0.9805523791625611\n",
            "Combined KPCA xTrain Shape: (1069, 22)\n",
            "Transformed Kernel xTest Shape: (22, 22)\n"
          ]
        }
      ],
      "source": [
        "# Combine the Data\n",
        "xTrainCombinedKernel = weightedKernelSum(alpha, beta, centeredxTrainPoly, centeredxTrainRBF)\n",
        "xTestCombinedKernel = weightedKernelSum(alpha, beta, centeredxTestPoly, centeredxTestRBF)\n",
        "print(\"Trained Polynomial RBF Kernel Matrix Shape:\", xTrainCombinedKernel.shape)\n",
        "print(\"Test Polynomial RBF Kernel Matrix Shape:\", xTestCombinedKernel.shape)\n",
        "\n",
        "# Perform Eigendecomposition\n",
        "xTrainEigenvalues, xTrainEigenvectors = eigenDecomposition(xTrainCombinedKernel)\n",
        "\n",
        "# Apply PCA\n",
        "xTrainCombinedKPCA, xTrainNeededEigenvalues, xTrainVarRatio = performPCA(xTrainCombinedKernel, desiredVarianceRatio, xTrainEigenvalues, xTrainEigenvectors)\n",
        "print(\"Combined KPCA xTrain Shape:\", xTrainCombinedKPCA.shape)\n",
        "\n",
        "# Apply Test Data Transform\n",
        "xTestTransformedKernel = np.dot(xTestCombinedKernel, xTrainEigenvectors[:,:xTrainNeededEigenvalues])\n",
        "print(\"Transformed Kernel xTest Shape:\", xTestTransformedKernel.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d72117-064b-4b0e-950f-ee651bff10a4",
      "metadata": {
        "id": "f6d72117-064b-4b0e-950f-ee651bff10a4",
        "outputId": "2a3a69da-89aa-4110-a787-1dd5d9b82555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Metric: 50.0\n"
          ]
        }
      ],
      "source": [
        "# Check Accuracy Metric\n",
        "xTrainCombinedKPCA, xTestTransformedKernel, yTrain, yTest, yPredict = naiveGaussianClassifier(xTrainCombinedKPCA, xTestTransformedKernel, yTrain, yTest)\n",
        "accuracyScore = accuracyMetric(yTest, yPredict)\n",
        "print(\"Accuracy Metric:\", accuracyScore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3a4f56-a5a4-4c8f-8074-970a99ab296a",
      "metadata": {
        "id": "8a3a4f56-a5a4-4c8f-8074-970a99ab296a"
      },
      "outputs": [],
      "source": [
        "# Part 3: Testing and Evaluation\n",
        "# 3.1 Preparing the Data:\n",
        "# A. Split the Lung Data Frame into Train and Test Datasets\n",
        "# Train and Test Data\n",
        "xTrainNew, xTestNew, yTrainNew, yTestNew = train_test_split(newLungData,labelLungData,test_size=.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b454e7ef-1516-424d-94c7-f0538fa3231d",
      "metadata": {
        "id": "b454e7ef-1516-424d-94c7-f0538fa3231d",
        "outputId": "97bf7095-585b-40ae-f655-c1a8aa6f2352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RBF Kernel\n",
            "RBF X Train Reduced Shape: (1069, 5)\n",
            "RBF X Test Reduced Shape: (22, 5)\n",
            "\n",
            "Polynomial Kernel\n",
            "Polynomial X Train Reduced Shape: (1069, 5)\n",
            "Polynomial X Test Reduced Shape: (22, 5)\n",
            "\n",
            "Linear Kernel\n",
            "Linear X Train Reduced Shape: (1069, 5)\n",
            "Linear X Test Reduced Shape: (22, 5)\n",
            "\n",
            "Combined RBF and Poly Kernel\n",
            "Combined RBF and Poly X Train Reduced Shape: (1069, 5)\n",
            "Combined RBF and Poly X Test Reduced Shape: (22, 5)\n"
          ]
        }
      ],
      "source": [
        "# B. Use the PCA and KPCA models (RBF, Polynomial, Linear, and combined kernels)\n",
        "# trained on the Train dataset to transform the Test dataset.\n",
        "# Kernels\n",
        "sklearnRBF = KernelPCA(n_components=5, kernel='rbf')\n",
        "sklearnPoly = KernelPCA(n_components=5, kernel='poly')\n",
        "sklearnLinear = KernelPCA(n_components=5, kernel='linear')\n",
        "\n",
        "# C. Ensure the Dimensionality Reduction is Consistent with the Training Data.\n",
        "# RBF\n",
        "xTrainReducedRBF = sklearnRBF.fit_transform(xTrainNew)\n",
        "xTestReducedRBF = sklearnRBF.transform(xTestNew)\n",
        "print(\"RBF Kernel\")\n",
        "print(\"RBF X Train Reduced Shape:\", xTrainReducedRBF.shape)\n",
        "print(\"RBF X Test Reduced Shape:\", xTestReducedRBF.shape)\n",
        "\n",
        "# Poly\n",
        "xTrainReducedPoly = sklearnPoly.fit_transform(xTrainNew)\n",
        "xTestReducedPoly = sklearnPoly.transform(xTestNew)\n",
        "print(\"\\nPolynomial Kernel\")\n",
        "print(\"Polynomial X Train Reduced Shape:\", xTrainReducedPoly.shape)\n",
        "print(\"Polynomial X Test Reduced Shape:\", xTestReducedPoly.shape)\n",
        "\n",
        "# Linear\n",
        "xTrainReducedLinear = sklearnLinear.fit_transform(xTrainNew)\n",
        "xTestReducedLinear = sklearnLinear.transform(xTestNew)\n",
        "print(\"\\nLinear Kernel\")\n",
        "print(\"Linear X Train Reduced Shape:\", xTrainReducedLinear.shape)\n",
        "print(\"Linear X Test Reduced Shape:\", xTestReducedLinear.shape)\n",
        "\n",
        "# Combined RBF and Polynomial\n",
        "xTrainReducedCombined = weightedKernelSum(alpha, beta, xTrainReducedRBF, xTrainReducedPoly)\n",
        "xTestReducedCombined = weightedKernelSum(alpha, beta, xTestReducedRBF, xTestReducedPoly)\n",
        "\n",
        "# Combined RBF and Polynomial\n",
        "print(\"\\nCombined RBF and Poly Kernel\")\n",
        "print(\"Combined RBF and Poly X Train Reduced Shape:\", xTrainReducedCombined.shape)\n",
        "print(\"Combined RBF and Poly X Test Reduced Shape:\", xTestReducedCombined.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc5ab7d-3916-4f63-b1e7-4d07e5235e9b",
      "metadata": {
        "id": "1fc5ab7d-3916-4f63-b1e7-4d07e5235e9b",
        "outputId": "37329fea-3a8d-4df6-fea0-d60ac3b83213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Covariance Matrix:\n",
            " [[ 3.64132003e+07  3.63754207e+07  3.63903211e+07 ...  2.05735354e+05\n",
            "   1.37170778e+07 -5.05024303e+01]\n",
            " [ 3.63754207e+07  3.63447280e+07  3.63557087e+07 ...  2.02655549e+05\n",
            "   1.35841085e+07 -5.17544440e+01]\n",
            " [ 3.63903211e+07  3.63557087e+07  3.63742618e+07 ...  2.04431667e+05\n",
            "   1.39865996e+07 -5.32241424e+01]\n",
            " ...\n",
            " [ 2.05735354e+05  2.02655549e+05  2.04431667e+05 ...  1.47418361e+05\n",
            "   8.95987577e+05 -1.25884123e+01]\n",
            " [ 1.37170778e+07  1.35841085e+07  1.39865996e+07 ...  8.95987577e+05\n",
            "   7.03172944e+08 -2.95837066e+02]\n",
            " [-5.05024303e+01 -5.17544440e+01 -5.32241424e+01 ... -1.25884123e+01\n",
            "  -2.95837066e+02  7.30344184e-01]]\n",
            "\n",
            "Covariance Matrix Shape: (1882, 1882)\n"
          ]
        }
      ],
      "source": [
        "# 3.2 Covariance Matrix Analysis:\n",
        "# A. Calculate the Covariance Matrix of the Dataset.\n",
        "print(\"Covariance Matrix:\\n\", covarianceMatrix)\n",
        "print(\"\\nCovariance Matrix Shape:\", covarianceMatrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed2c3dcd-67c9-4043-8534-e1a171c558a7",
      "metadata": {
        "id": "ed2c3dcd-67c9-4043-8534-e1a171c558a7",
        "outputId": "b4f74bb3-2208-4f10-8185-35a109cbd321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 Covariance Matrix Features:\n",
            " [ 285  189  595  200  273  305  352 1880   25  226]\n",
            "\n",
            "Top 10 Covariance Matrix Features Shape: (10,)\n"
          ]
        }
      ],
      "source": [
        "# B. Identify the Top 10 Features with the Highest Covariance Values.\n",
        "diagonalCovarianceMatrix = np.diag(covarianceMatrix)\n",
        "sortDiagonalCovMatrix = np.argsort(diagonalCovarianceMatrix)[::-1]\n",
        "topFeatures = sortDiagonalCovMatrix[:10]\n",
        "\n",
        "print(\"Top 10 Covariance Matrix Features:\\n\", topFeatures)\n",
        "print(\"\\nTop 10 Covariance Matrix Features Shape:\", topFeatures.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23df35c5-b454-49cd-9cca-c8be96e585ad",
      "metadata": {
        "id": "23df35c5-b454-49cd-9cca-c8be96e585ad",
        "outputId": "59a4c79f-7875-4499-ab7b-54b6ad83355d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Features Dataset shape: (1091, 10)\n",
            "RBF Kernel\n",
            "RBF X Train Reduced Shape: (1069, 5)\n",
            "RBF X Test Reduced Shape: (22, 5)\n",
            "Accuracy Metric: 50.0\n"
          ]
        }
      ],
      "source": [
        "# C. Extract the Top 10 Features and Evaluate the Classification Performance Using Accuracy Metrics.\n",
        "# Extract\n",
        "topFeaturesMatrix = lungData.iloc[:, topFeatures]\n",
        "print(\"Top Features Dataset shape:\", topFeaturesMatrix.shape)\n",
        "\n",
        "# Train and Test\n",
        "newTopFeatures = topFeaturesMatrix\n",
        "xTrainTop, xTestTop, yTrainTop, yTestTop = train_test_split(newTopFeatures,labelLungData,test_size=.02)\n",
        "\n",
        "# KPCA\n",
        "sklearnTopRBF = KernelPCA(n_components=5, kernel='rbf')\n",
        "xTrainTopReducedRBF = sklearnTopRBF.fit_transform(xTrainTop)\n",
        "xTestTopReducedRBF = sklearnTopRBF.transform(xTestTop)\n",
        "print(\"RBF Kernel\")\n",
        "print(\"RBF X Train Reduced Shape:\", xTrainTopReducedRBF.shape)\n",
        "print(\"RBF X Test Reduced Shape:\", xTestTopReducedRBF.shape)\n",
        "\n",
        "# Check Accuracy Metric\n",
        "xTrainTopReducedRBF, xTestTopReducedRBF, yTrainTop, yTestTop, yPredictTop = naiveGaussianClassifier(xTrainTopReducedRBF, xTestTopReducedRBF, yTrainTop, yTestTop)\n",
        "topAccuracyScore = accuracyMetric(yTestTop, yPredictTop)\n",
        "print(\"Accuracy Metric:\", topAccuracyScore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f02025bd-deee-4211-9df6-9b79b80a4492",
      "metadata": {
        "id": "f02025bd-deee-4211-9df6-9b79b80a4492"
      },
      "outputs": [],
      "source": [
        "# 3.3 Classification Experiment:\n",
        "# A. Implement the Following Classifiers:\n",
        "# B. Test the classifiers on:\n",
        "# C. For each classifier and dimensionality reduction technique,\n",
        "# find the best number of components that yield the highest classification accuracy.\n",
        "# D. Plot accuracy versus the number of components for each classifier and dimensionality reduction technique.\n",
        "# E. Evaluate the classification performance using accuracy metrics (accuracy, precision, recall)\n",
        "# and compare the effectiveness of PCA features, KPCA features, and top 10 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "424a4169-e856-46f1-b567-4aebe05a4df7",
      "metadata": {
        "id": "424a4169-e856-46f1-b567-4aebe05a4df7"
      },
      "outputs": [],
      "source": [
        "#  - Whole data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe896c4-dbe3-43b1-ae3e-77070ccba702",
      "metadata": {
        "id": "cfe896c4-dbe3-43b1-ae3e-77070ccba702"
      },
      "outputs": [],
      "source": [
        "#  - Data reduced by PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a3e340-fef9-450e-8348-2513db2fa755",
      "metadata": {
        "id": "97a3e340-fef9-450e-8348-2513db2fa755"
      },
      "outputs": [],
      "source": [
        "#  - Data reduced by KPCA with RBF kernel\n",
        "kdaSklearnRBF = KernelPCA(n_components=5, kernel='rbf')\n",
        "\n",
        "#  - Minimum Distance Classifier (build from scratch)\n",
        "xTrainMDC, xTestMDC, yTrainMDC, yTestMDC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - Bayes Classifier (build from scratch)\n",
        "xTrainBC, xTestBC, yTrainBC, yTestBC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - Naive Bayes Classifier (using sklearn)\n",
        "xTrainNBC, xTestNBC, yTrainNBC, yTestNBC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - KNN Classifier (using sklearn)\n",
        "xTrainKNN, xTestKNN, yTrainKNN, yTestKNN = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - LDA Classifier (using sklearn)\n",
        "xTrainLDA, xTestLDA, yTrainLDA, yTestLDA = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - Kernel Discriminant Analysis (KDA) with RBF kernel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a61f43a-2b8f-4b76-9f5e-cb9b1d3d1d70",
      "metadata": {
        "id": "9a61f43a-2b8f-4b76-9f5e-cb9b1d3d1d70"
      },
      "outputs": [],
      "source": [
        "#  - Data reduced by KPCA with Polynomial kernel\n",
        "kdaSklearnPoly = KernelPCA(n_components=5, kernel='poly')\n",
        "\n",
        "#  - Minimum Distance Classifier (build from scratch)\n",
        "xTrainMDC, xTestMDC, yTrainMDC, yTestMDC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - Bayes Classifier (build from scratch)\n",
        "xTrainBC, xTestBC, yTrainBC, yTestBC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - Naive Bayes Classifier (using sklearn)\n",
        "xTrainNBC, xTestNBC, yTrainNBC, yTestNBC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - KNN Classifier (using sklearn)\n",
        "xTrainKNN, xTestKNN, yTrainKNN, yTestKNN = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - LDA Classifier (using sklearn)\n",
        "xTrainLDA, xTestLDA, yTrainLDA, yTestLDA = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "\n",
        "#  - Kernel Discriminant Analysis (KDA) with Polynomial kernels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4c426d-d42f-457c-b312-14a5695c36f9",
      "metadata": {
        "id": "dd4c426d-d42f-457c-b312-14a5695c36f9"
      },
      "outputs": [],
      "source": [
        "#  - Data reduced by KPCA with Linear kernel\n",
        "kdaSklearnLinear = KernelPCA(n_components=5, kernel='linear')\n",
        "\n",
        "#  - Minimum Distance Classifier (build from scratch)\n",
        "xTrainMDC, xTestMDC, yTrainMDC, yTestMDC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - Bayes Classifier (build from scratch)\n",
        "xTrainBC, xTestBC, yTrainBC, yTestBC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - Naive Bayes Classifier (using sklearn)\n",
        "xTrainNBC, xTestNBC, yTrainNBC, yTestNBC = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - KNN Classifier (using sklearn)\n",
        "xTrainKNN, xTestKNN, yTrainKNN, yTestKNN = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "#  - LDA Classifier (using sklearn)\n",
        "xTrainLDA, xTestLDA, yTrainLDA, yTestLDA = train_test_split(newLungData,labelLungData,test_size=.02)\n",
        "\n",
        "\n",
        "#  - Kernel Discriminant Analysis (KDA) with Linear kernel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3734cfc9-b3c3-4eae-95c4-45eaa3a5bf17",
      "metadata": {
        "id": "3734cfc9-b3c3-4eae-95c4-45eaa3a5bf17"
      },
      "outputs": [],
      "source": [
        "#  - Data reduced by the top 10 features(PCA and KPCA here by using SKLEARN)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}